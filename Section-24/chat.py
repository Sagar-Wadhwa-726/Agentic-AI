from typing_extensions import TypedDict
from typing import Annotated
from langgraph.graph.message import add_messages
from langgraph.graph import StateGraph, START, END
from langchain.chat_models import init_chat_model

from dotenv import load_dotenv
load_dotenv()

llm = init_chat_model(
    model="gpt-4.1-mini",
    model_provider="openai"
)

# this will keep on adding the data to the list, initially this will be having the user query. Then it will also contain the response generated by the LLM
class State(TypedDict):
    messages: Annotated[list, add_messages]


# in this particular function we can also modify the state
# state = {messages: ["Hey there"]}
# node runs chatbot(state : ["Hey There"]) -> ["Hi, This is a message from Chat Bot"]
# state = {"messages" : ["Hey There", "Hi, this is a message from chatbot node"]}
def chatbot(state: State):
    response = llm.invoke(state.get("messages"))
    return {
        "messages" : [response]
    }

def samplenode(state: State):
    print("\n\nInside the sample node ! ", state)
    return {
        "messages" : ["Sample message appended"]
    }

# State is the schema, state graph will give a graph builder variable
# now the state is ready and the graph builder is ready
graph_builder = StateGraph(State)

# adding nodes in the graph
# Nodes are just a fucntion which does a specific task
graph_builder.add_node("chatbot", chatbot)
graph_builder.add_node("samplenode", samplenode)

# defining edges - start and end have to be defined
# (START) -> chatbot -> samplenode -> (END)
graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", "samplenode")
graph_builder.add_edge("samplenode", END)
graph = graph_builder.compile()

# while invoking the graph we have to provide the initial state
updated_state = graph.invoke(State({
    "messages" : ["Hi, My name is Sagar Wadhwa"]
}))
print("\n\nUpdated State : ", updated_state)